{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d70cd309-c49b-4f83-bb72-02468b42a9d9",
   "metadata": {},
   "source": [
    "# CAP 4630 – Artificial Intelligence\n",
    "**Name:** Xavier Soto \n",
    "**UCF ID:** 5601517 \n",
    "## HW 1 Problem 1 (30 points) – Linear Regression via Gradient Descent\n",
    "\n",
    "We are given dataset `D3.csv` that has 3 variables $x_1$, $x_2$, $x_3$ and one dependendent variable.\n",
    "The tasks are:\n",
    "\n",
    "1. Run the linear regression using a gradiend descent with the given variables\n",
    "2. Report the linear model $\\theta_1$, $\\theta_2$, $\\theta_3$\n",
    "3.  Predict y for the new inputs\n",
    "                 (1,1,1), (2,0,4), (3,2,1)\n",
    "4. Demonstrate convergence through the cost function J($\\theta$) plot over the iterations\n",
    "5. Verify with the Normal Equation (the analytical solution)\n",
    "\n",
    "The Following python code cell reads the dataset `D3.csv` and Splits the features $x$ and $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1eed2b4d-5fa4-49c7-8008-626d7ee4d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read CSV, assign column names\n",
    "df = pd.read_csv(\"D3.csv\", header=None, names=[\"x1\",\"x2\",\"x3\",\"y\"])\n",
    "\n",
    "# 2) Split features/target (be sure NOT to include 'y' in X)\n",
    "X = df[[\"x1\",\"x2\",\"x3\"]].values.astype(float)   # (m, 3)\n",
    "y = df[[\"y\"]].values.astype(float)              # (m, 1)\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611cd430-9dd4-47ed-be3a-adde76b8891c",
   "metadata": {},
   "source": [
    "# Preprocessing Training Data\n",
    "\n",
    "Before running the gradient descent, we Standardize each feature:\n",
    "\n",
    "$$x_j = \\frac{ x_j - \\mu }{ \\sigma }$$\n",
    "\n",
    "- $\\mu_j$ = The mean of feature $j$ in the training set\n",
    "- $\\sigma_j$ = The Standard Deviation of the Feature $j$ in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c035aa81-6b18-499f-b972-05dc1ed14ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "mu = X.mean(axis=0)\n",
    "sigma = X.std(axis=0, ddof=0)\n",
    "X_std = (X - mu) / sigma\n",
    "\n",
    "# Design matrix: add bias column of ones\n",
    "m = X_std.shape[0]\n",
    "X_design = np.hstack([np.ones((m, 1)), X_std])  # (m, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb313b8d-38a8-4947-b4f2-10d44b160d33",
   "metadata": {},
   "source": [
    "- ## Cost Function (MSE):\n",
    "  \n",
    "$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( h_{\\theta}(x^{(i)}) - y^{(i)} \\right)^2$$\n",
    "\n",
    "where\n",
    "$$\n",
    "h_{\\theta}(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c13c6446-b4e6-4ea7-8933-36c6c091a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, theta):\n",
    "    \n",
    "    ## Compute cost J(θ) using:\n",
    "    ## J(θ) = (1 / 2m) Σ (hθ(x^(i)) - y^(i))^2\n",
    "    \n",
    "    m = len(y)\n",
    "    total = 0.0\n",
    "    \n",
    "    for i in range(m):\n",
    "\n",
    "        # compute prediction for row i\n",
    "        prediction = 0\n",
    "        for j in range(X.shape[1]):\n",
    "            prediction += theta[j, 0] * X[i, j]\n",
    "        error = prediction - y[i, 0]\n",
    "        total += error**2\n",
    "\n",
    "    J = total / (2 * m)\n",
    "    return J\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88e4acef-e96a-4c8f-88bb-688a5144c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.524438459185472\n"
     ]
    }
   ],
   "source": [
    "# Initializing all of the thetas to zeros\n",
    "theta_init = np.zeros((4,1))\n",
    "print(compute_cost(X_design, y, theta_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2d183-d6e2-410d-9bc3-8d42326b32a9",
   "metadata": {},
   "source": [
    "- **Initial Cost (θ = 0)**\n",
    "\n",
    "When all parameters $ \\theta $ are set to zero, the hypothesis is:\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = 0\n",
    "$$\n",
    "\n",
    "Thus, the cost becomes:\n",
    "\n",
    "$$\n",
    "J(\\theta=0) = \\frac{1}{2m} \\sum_{i=1}^{m} \\big( y^{(i)} \\big)^2\n",
    "$$\n",
    "\n",
    "For our dataset, the computed value is:\n",
    "\n",
    "$$\n",
    "J(\\theta=0) = 5.24438459185472\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f17962-2946-44d6-9f81-7e1663ce5cc9",
   "metadata": {},
   "source": [
    "## Gradient Descent Rule\n",
    "\n",
    "Update step:\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^m \\big( h_{\\theta}(x^{(i)}) - y^{(i)} \\big) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "- α = learning rate  \n",
    "- m = sample count  \n",
    "- x0 = 1 (bias)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ff7b41e-4042-4372-988d-2ee050e93393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = []\n",
    "\n",
    "    for it in range(iterations):\n",
    "        new_theta = theta.copy()\n",
    "        \n",
    "        for j in range(X.shape[1]):\n",
    "            summation = 0.0\n",
    "\n",
    "            #Summation over the training given examples\n",
    "            for i in range(m):\n",
    "                #h theta x^i\n",
    "                prediction = 0.0\n",
    "                for k in range(X.shape[1]):\n",
    "                    prediction += theta[k,0] * X[i,k]\n",
    "                error = prediction - y[i, 0]\n",
    "                summation += error * X[i, j]\n",
    "                    \n",
    "\n",
    "            #Update rule for Theta j     \n",
    "            new_theta[j, 0] = theta[j, 0] - alpha * (1/m) * summation\n",
    "\n",
    "        #Update Thetha\n",
    "        theta = new_theta\n",
    "\n",
    "        #Save cost for monitoring convergence\n",
    "        cost_history.append(compute_cost(X, y, theta))\n",
    "\n",
    "    return theta, cost_history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a6bf6a3-ec3c-44a3-80cd-2716de563e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "θ and Cost\n",
      "Final θ: [ 1.85127565 -2.33694953  0.62111698 -0.3073479 ]\n",
      "Final cost: 0.7384642415649307\n"
     ]
    }
   ],
   "source": [
    "# Run gradient descent\n",
    "theta_init = np.zeros((4,1))\n",
    "alpha = 0.01\n",
    "iterations = 10000\n",
    "\n",
    "theta_final, J_hist = gradient_descent(X_design, y, theta_init, alpha, iterations)\n",
    "\n",
    "print(\"θ and Cost\")\n",
    "print(\"Final θ:\", theta_final.flatten())\n",
    "print(\"Final cost:\", J_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "404581d5-4a40-49a2-9ba3-7e71114f1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute h(theta)(x) \n",
    "def pred(x_row, theta):\n",
    "\n",
    "    prediction = 0.0\n",
    "    for j in range (len(x_row)):\n",
    "        prediction += theta[j,0] * x_row[j]\n",
    "    return prediction \n",
    "\n",
    "#The original input\n",
    "\n",
    "X_new = np.array ([[1,1,1], [2,0,4], [3,2,1]], dtype = float)\n",
    "\n",
    "#Standardizing using the mean and std from training\n",
    "X_new_std = (X_new - mu) / sigma\n",
    "\n",
    "#Add an intercept column\n",
    "X_new_design = np.hstack([np.ones((X_new_std.shape[0], 1)), X_new_std])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "344398eb-d82b-4f45-924d-f8eb83b956a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      " \n",
      "Input [1. 1. 1.] -> Predicted y value = 3.5774093743331425\n",
      "Input [2. 0. 4.] -> Predicted y value = 0.24432117280828447\n",
      "Input [3. 2. 1.] -> Predicted y value = 0.10253417286413627\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#The predictions\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(\" \")\n",
    "\n",
    "for i in range(X_new_design.shape[0]):\n",
    "    y_hat = pred(X_new_design[i], theta_final)\n",
    "    print(f\"Input {X_new[i]} -> Predicted y value = {y_hat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9c28b-113d-4210-9800-50c3e926bba8",
   "metadata": {},
   "source": [
    "## Convergence Plot\n",
    "\n",
    "We plot the cost function versus the number of iterations to show convergence.\n",
    "\n",
    "- Initially, cost is high (θ = 0).  \n",
    "- Each iteration updates θ using gradient descent.  \n",
    "- The curve decreases smoothly and flattens once convergence is reached.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ffdc573-93a8-4356-8315-3c66e4fe0747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#We run gradient descent and then\n",
    "Theta_final, J_hist = gradient_descent(X_design, y, theta_init, alpha, iterations)\n",
    "\n",
    "#Plot the loss curve using matplotlib\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(J_hist)), J_hist, color='red')\n",
    "plt.xlabel(\"Iterations\", fontsize=14)\n",
    "plt.ylabel(\"Cost J(θ)\", fontsize=14)\n",
    "plt.title(\"Convergence of Gradient Descent\", fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c17b3-6155-4e7b-ac96-15d921fb4fad",
   "metadata": {},
   "source": [
    "**Normal Equation:**  \n",
    "\n",
    "$ \\theta = (X^T X)^{-1} X^T y $\n",
    "\n",
    "\n",
    "**Predictions**\n",
    "\n",
    "Compare outputs from Gradient Descent and Normal Equation.  \n",
    "Both should be nearly identical.  \n",
    "\n",
    "\n",
    "\n",
    "**Results**\n",
    "\n",
    "- Parameters from GD and NE match to numerical precision.  \n",
    "- Predictions align.  \n",
    "- Max difference is negligible.  \n",
    "\n",
    "The following is in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "821e2251-7ea8-40f5-bea0-4c3a5516d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "XT_X = X_design.T @ X_design\n",
    "XT_y = X_design.T @ y\n",
    "theta_ne = np.linalg.inv(XT_X) @ XT_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4496d-2f7b-4aca-9b30-a269c3e5d913",
   "metadata": {},
   "source": [
    "-**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2f6d219-9177-4d8a-bfea-ed169ab988cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input [1. 1. 1.] → Gradient Descent =3.57741, Normal Equation =3.57741, diff=2.087219e-14\n",
      "Input [2. 0. 4.] → Gradient Descent =0.24432, Normal Equation =0.24432, diff=1.054712e-14\n",
      "Input [3. 2. 1.] → Gradient Descent =0.10253, Normal Equation =0.10253, diff=1.210143e-14\n"
     ]
    }
   ],
   "source": [
    "#Predictions with Gradient Descent\n",
    "preds_gradDesc = [pred(X_new_design[i], theta_final) for i in range(X_new_design.shape[0])]\n",
    "\n",
    "#Predictions from Normal Equation\n",
    "preds_normEquation = [pred(X_new_design[i], theta_ne) for i in range(X_new_design.shape[0])]\n",
    "\n",
    "# compare results\n",
    "for i, x_row in enumerate(X_new):\n",
    "    print(f\"Input {x_row} → Gradient Descent ={preds_gradDesc[i]:.5f}, Normal Equation ={preds_normEquation[i]:.5f}, diff={abs(preds_gradDesc[i]-preds_normEquation[i]):.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7512fe-f275-4116-8be9-b6b569bff605",
   "metadata": {},
   "source": [
    "## Final Results\n",
    "\n",
    "The final results are the following:\n",
    "\n",
    "- The parameters obtained by the learning of the Gradient Descent and the Normal Equation\n",
    "- The Predictions for the requested inputs (1,1,1), (2,0,4), and (3,2,1)\n",
    "- A check of the maximum difference between the two $\\theta$ vectors (these should be small which would confirm its correctness)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e5889-d65b-42bb-8094-68a2c909d07d",
   "metadata": {},
   "source": [
    "- **Parameters ($\\theta$)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93509dac-dd31-4f48-8eed-0ce64c06dc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent θ: [ 1.85127565 -2.33694953  0.62111698 -0.3073479 ]\n",
      "Normal Equation θ: [ 1.85127565 -2.33694953  0.62111698 -0.3073479 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Descent θ:\", theta_final.flatten())\n",
    "print(\"Normal Equation θ:\", theta_ne.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec344da-237d-4c5d-8fa3-b5162d7692cc",
   "metadata": {},
   "source": [
    "- **Predictions**\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f5a99ec-e7f1-4cdd-8567-56c8d52098b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input[1. 1. 1.] -> ŷ_Gradient Descent=3.57741, ŷ_Normal Equation=3.57741\n",
      "Input[2. 0. 4.] -> ŷ_Gradient Descent=0.24432, ŷ_Normal Equation=0.24432\n",
      "Input[3. 2. 1.] -> ŷ_Gradient Descent=0.10253, ŷ_Normal Equation=0.10253\n"
     ]
    }
   ],
   "source": [
    "for i, x_orig in enumerate(X_new):\n",
    "    print(f\"Input{x_orig} -> ŷ_Gradient Descent={preds_gradDesc[i]:.5f}, ŷ_Normal Equation={preds_normEquation[i]:.5f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b3037-6bfc-4c10-b0b4-4b77d595ce6e",
   "metadata": {},
   "source": [
    "- **Difference Check**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c193c70-3163-4698-ba7c-a2c2f8f0f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max |θ_Gradient Descent - θ_Normal Equation| = 2.1760371282653068e-14\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMax |θ_Gradient Descent - θ_Normal Equation| =\", np.max(np.abs(theta_final - theta_ne)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8709fa5c-c3f4-4ed9-b842-9ce0936d8ef9",
   "metadata": {},
   "source": [
    "# Final Results — Problem 1\n",
    "\n",
    "**Model:**  \n",
    "\n",
    "$$\n",
    "\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3\n",
    "$$  \n",
    "\n",
    "---\n",
    "\n",
    "**Estimated Parameters (θ):**\n",
    "\n",
    "Both gradient descent and the normal equation give the same solution (within machine precision):  \n",
    "\n",
    "$$\n",
    "\\theta_0 \\approx 5.314, \\;\n",
    "\\theta_1 \\approx -2.004, \\;\n",
    "\\theta_2 \\approx 0.533, \\;\n",
    "\\theta_3 \\approx -0.266\n",
    "$$  \n",
    "\n",
    "---\n",
    "\n",
    "**Predicted Values:**  \n",
    "\n",
    "- (1,1,1) → $\\hat{y} \\approx 3.58$  \n",
    "- (2,0,4) → $\\hat{y} \\approx 0.24$  \n",
    "- (3,2,1) → $\\hat{y} \\approx 0.10$  \n",
    "\n",
    "---\n",
    "\n",
    "**Checks:**  \n",
    "\n",
    "- Gradient Descent and Normal Equation converge to the same θ.  \n",
    "- Predictions consistent across methods.  \n",
    "- Cost curve confirms convergence.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75b7df-f59e-4c61-a24d-7f0bf5dc7b66",
   "metadata": {},
   "source": [
    "## CAP 4630 - HW1, Problem 2: Normal Equation Approach\n",
    "\n",
    "We want a closed-form solution for linear regression with three features $(x_1, x_2, x_3)$ and intercept.  \n",
    "\n",
    "**Closed-form formula:**  \n",
    "\n",
    "$$\n",
    "\\theta = (X^T X)^{-1} X^T y\n",
    "$$  \n",
    "\n",
    "---\n",
    "\n",
    "### Setup\n",
    "\n",
    "- Extend X with a bias column (all 1s).  \n",
    "- Solve for parameters $(\\theta_0, \\theta_1, \\theta_2, \\theta_3)$.  \n",
    "- Verify shapes: $X \\in \\mathbb{R}^{m \\times 4}, \\; \\theta \\in \\mathbb{R}^4, \\; y \\in \\mathbb{R}^m$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6a1549-60ba-4c86-b264-b494a5109f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# feature matrix (time, jiggle, scroll)\n",
    "X_raw = np.array([\n",
    "    [232, 33, 402],\n",
    "    [10, 32, 46],\n",
    "    [6347, 343, 2431],\n",
    "    [512, 101, 31],\n",
    "    [441, 212, 112],\n",
    "    [453, 53, 99],\n",
    "    [2, 2, 1],\n",
    "    [332, 79, 104],\n",
    "    [182, 20, 89],\n",
    "    [123, 223, 203],\n",
    "    [424, 12, 31]\n",
    "], dtype=float)\n",
    "\n",
    "# target values (sales(y))\n",
    "y = np.array([\n",
    "    2201, 0, 7650, 5599, 8900, 1742, 0, 1215, 699, 2101, 8789\n",
    "], dtype=float).reshape(-1,1)\n",
    "\n",
    "# add bias term\n",
    "m = X_raw.shape[0]\n",
    "X = np.hstack([np.ones((m, 1)), X_raw])\n",
    "y= y.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1985afe-15b4-48ee-8369-def3803f60cb",
   "metadata": {},
   "source": [
    "## How to Derive the Normal Equation\n",
    "\n",
    "Model: $y$ = $X$ $\\theta$\n",
    "\n",
    "Objective (MSE):\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m} \\, \\| X\\theta - y \\|_2^2$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689cfac-39d0-4540-8c36-bc09902b4dda",
   "metadata": {},
   "source": [
    "**Gradient**\n",
    "\n",
    "The gradient of $J(\\theta)$ is:  \n",
    "\n",
    "$$\n",
    "\\nabla J(\\theta) = \\frac{1}{m} X^T (X\\theta - y)\n",
    "$$  \n",
    "\n",
    "At optimum, gradient = 0:  \n",
    "\n",
    "\n",
    "$$X^T (X\\theta - y) = 0 \\quad \\Rightarrow \\quad \n",
    "\\theta = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e5516d-5ca0-4caf-bd2a-b461cc681987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameters\n",
      "[θ_0, θ_1, θ_2, θ_3] =[2000.047799, 4.472079, 14.883003, -11.308186]\n"
     ]
    }
   ],
   "source": [
    "#We Compute the closed-form θ\n",
    "XT_X = X.T @ X\n",
    "XT_y = X.T @ y\n",
    "theta = np.linalg.inv(XT_X) @ XT_y\n",
    "\n",
    "#The format output\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "theta_row = theta.ravel()\n",
    "print(\"Final parameters\\n[θ_0, θ_1, θ_2, θ_3] =[{:.6f}, {:.6f}, {:.6f}, {:.6f}]\".format(*theta_row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316f0b4-e261-483f-8864-60935977232e",
   "metadata": {},
   "source": [
    "### Final Results\n",
    "\n",
    "Using the **closed-form solution** of linear regression:\n",
    "\n",
    "\n",
    "$$\\theta = (X^\\top X)^{-1} X^\\top y$$\n",
    "\n",
    "\n",
    "The parameter vector (with intercept first) is:\n",
    "\n",
    "\n",
    "$$\\theta =\n",
    "\\begin{bmatrix}\n",
    "2626.268614 \\\\\n",
    "0.420484 \\\\\n",
    "12.716237 \\\\\n",
    "-6.496562\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "Therefor, the fitted model is the following:\n",
    "\n",
    "\n",
    "$$\\hat{y} = 2626.268614 \\;+\\; 0.420484x_1 \\;+\\; 12.716237x_2 \\;-\\; 6.496562x_3$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
